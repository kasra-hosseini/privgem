{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifty-telling",
   "metadata": {},
   "source": [
    "# Artificial and synthetic datasets\n",
    "\n",
    "In this notebook, instead of using and synthesizing *real* datasets, we first create *artifical* datasets and then analyze the outputs. This way, we can engineer some required features in the artifical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve issue with autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from joblib import load as jload\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from privgem import tabular_ppgm\n",
    "from privgem import tabular_patectgan\n",
    "from privgem import tabular_metrics\n",
    "from privgem import tabular_utils\n",
    "from privgem import tabular_artificial\n",
    "from privgem import rbo_metric\n",
    "\n",
    "from utils import train_save_pate_models\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1364)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-republic",
   "metadata": {},
   "source": [
    "## Create an artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "# Classes\n",
    "n_classes = 2\n",
    "class_weights = [0.5, 0.5]\n",
    "n_clusters_per_class = 1\n",
    "# Features\n",
    "n_features=5\n",
    "n_informative=5\n",
    "n_redundant=0\n",
    "n_repeated=0\n",
    "# Control \"noise\"\n",
    "flip_y=0.1\n",
    "class_sep=1.0\n",
    "\n",
    "# number of categorical columns and their bins\n",
    "n_categorical=5\n",
    "n_categorical_bins=[5, 5, 5, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-religious",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y, categories = \\\n",
    "    tabular_artificial.make_table(n_samples=n_samples,\n",
    "                                  n_classes=n_classes,\n",
    "                                  class_weights=class_weights,\n",
    "                                  n_clusters_per_class=n_clusters_per_class,\n",
    "                                  n_features=n_features, \n",
    "                                  n_informative=n_informative, \n",
    "                                  n_redundant=n_redundant, \n",
    "                                  n_repeated=n_repeated,\n",
    "                                  n_categorical=n_categorical,\n",
    "                                  n_categorical_bins=n_categorical_bins,\n",
    "                                  flip_y=flip_y, \n",
    "                                  class_sep=class_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-channels",
   "metadata": {},
   "source": [
    "## Utility of original/artifical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numerical and categorical columns\n",
    "num_columns, cat_columns = tabular_utils.extract_col_names_by_type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_corr_matrix = tabular_metrics.compute_associations(X, cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "custom_pipe = tabular_metrics.create_pipeline(num_columns, cat_columns, \n",
    "                                              categories=categories,\n",
    "                                              inp_classifer=RandomForestClassifier())\n",
    "                                              #inp_classifer=GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "test_size=0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-invention",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1_orig, auc_orig, roc_auc_orig, f_orig_built, f_orig_perm, f_orig_shap = \\\n",
    "    tabular_metrics.performance_classification(X_train, y_train, \n",
    "                                               X_test, y_test, \n",
    "                                               model_imp=custom_pipe,\n",
    "                                               pipe_classifier_name=\"classifier\")\n",
    "\n",
    "print(f\"F1:       {f1_orig:.3f}\\n\"\\\n",
    "      f\"AUC:      {auc_orig:.3f}\\n\"\\\n",
    "      f\"ROC-AUC:  {roc_auc_orig:.3f}\\n\"\\\n",
    "      f\"Features (built): {f_orig_built}\\n\"\\\n",
    "      f\"Features (perm) : {f_orig_perm}\\n\"\\\n",
    "      f\"Features (shap) : {f_orig_shap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features\n",
    "sorted_f_orig_built, _ = \\\n",
    "    tabular_utils.sort_feature_vector(f_orig_built, X_train.columns.to_list())\n",
    "sorted_f_orig_perm, _  = \\\n",
    "    tabular_utils.sort_feature_vector(f_orig_perm,  X_train.columns.to_list())\n",
    "sorted_f_orig_shap, sorted_f_orig_shap_val  = \\\n",
    "    tabular_utils.sort_feature_vector(f_orig_shap,  X_train.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-tuesday",
   "metadata": {},
   "source": [
    "## Shuffle columns, independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(df):     \n",
    "    df_shuffled = copy.deepcopy(df)\n",
    "\n",
    "    for indx in range(df_shuffled.shape[1]):\n",
    "        df_shuffled.iloc[:, indx] = np.random.permutation(df_shuffled.iloc[:, indx])\n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shuffled = shuffle(X_train)\n",
    "X_test_shuffled = shuffle(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_shuffled, auc_shuffled, roc_auc_shuffled, f_shuffled_built, f_shuffled_perm, f_shuffled_shap = \\\n",
    "    tabular_metrics.performance_classification(X_train_shuffled, y_train, \n",
    "                                               X_test_shuffled, y_test, \n",
    "                                               model_imp=custom_pipe,\n",
    "                                               pipe_classifier_name=\"classifier\")\n",
    "\n",
    "print(f\"F1:       {f1_shuffled:.3f}\\n\"\\\n",
    "      f\"AUC:      {auc_shuffled:.3f}\\n\"\\\n",
    "      f\"ROC-AUC:  {roc_auc_shuffled:.3f}\\n\"\\\n",
    "      f\"Features (built): {f_shuffled_built}\\n\"\\\n",
    "      f\"Features (perm) : {f_shuffled_perm}\\n\"\\\n",
    "      f\"Features (shap) : {f_shuffled_shap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the features\n",
    "sorted_f_shuffled_built, _ = \\\n",
    "    tabular_utils.sort_feature_vector(f_shuffled_built, X_train.columns.to_list())\n",
    "sorted_f_shuffled_perm, _  = \\\n",
    "    tabular_utils.sort_feature_vector(f_shuffled_perm,  X_train.columns.to_list())\n",
    "sorted_f_shuffled_shap, sorted_f_shuffled_shap_val  = \\\n",
    "    tabular_utils.sort_feature_vector(f_shuffled_shap,  X_train.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_f_orig_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_f_shuffled_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity between original and shuffled dataset\n",
    "cosine_sim_measure_shuffled = \\\n",
    "    tabular_metrics.cosine_sim(f_shuffled_shap, f_orig_shap)\n",
    "\n",
    "kl_div_measure_shuffled = tabular_metrics.kl_div(f_shuffled_shap, f_orig_shap)\n",
    "\n",
    "# RBO\n",
    "rbo_shuffled = rbo_metric(sorted_f_orig_shap, sorted_f_shuffled_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-syria",
   "metadata": {},
   "source": [
    "## Choose a synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesizer_method = \"pgm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-recovery",
   "metadata": {},
   "source": [
    "## Synthesize using PATE-CTGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pate-ctgan\":\n",
    "    list_eps = [0.4, 1, 10]\n",
    "    #list_nm = [4.2e-5, 1.05e-4, 9e-4]\n",
    "    list_nm = [4.2e-4, 1.05e-3, 9e-3]\n",
    "    list_mo = [1000, 100, 100]\n",
    "\n",
    "    list_save_log = [\n",
    "        \"./pate_00_40/patectgan_training.csv\",\n",
    "        \"./pate_01_00/patectgan_training.csv\",\n",
    "        \"./pate_10_00/patectgan_training.csv\",\n",
    "                     ]\n",
    "\n",
    "    list_save_model = [\n",
    "        \"./pate_00_40/model.pkl\",\n",
    "        \"./pate_01_00/model.pkl\",\n",
    "        \"./pate_10_00/model.pkl\",\n",
    "                     ]\n",
    "\n",
    "    batch_size = 64\n",
    "    device = \"default\" # or \"default\" or \"cpu\" or \"cuda:1\"\n",
    "    \n",
    "    discrete_columns = cat_columns + [\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pate-ctgan\":\n",
    "    # prepare data\n",
    "    Xy = X_train.copy()\n",
    "    Xy[\"label\"] = y_train\n",
    "    Xy[cat_columns] = Xy[cat_columns].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pate-ctgan\":\n",
    "    from parhugin import multiFunc\n",
    "    myproc = multiFunc(num_req_p=4)\n",
    "\n",
    "    for i in range(len(list_eps)):    \n",
    "        myproc.add_job(target_func=train_save_pate_models, \n",
    "                       target_args=(Xy, \n",
    "                                    discrete_columns,\n",
    "                                    list_eps[i], \n",
    "                                    batch_size,\n",
    "                                    list_nm[i], \n",
    "                                    list_mo[i],\n",
    "                                    list_save_log[i], \n",
    "                                    device, \n",
    "                                    list_save_model[i])\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pate-ctgan\":\n",
    "    myproc.run_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pate-ctgan\":\n",
    "    list_models = []\n",
    "    for i in range(len(list_save_model)):\n",
    "        list_models.append(jload(list_save_model[i]))\n",
    "\n",
    "    # plot the results\n",
    "    tabular_utils.plot_log_patectgan(filename=list_save_log[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-ancient",
   "metadata": {},
   "source": [
    "## Synthesize using PGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthesizer_method == \"pgm\":\n",
    "    num_iters = 5000\n",
    "    list_eps = [0.005, 0.01, 0.1, 0.4, 1, 4.0, 10]\n",
    "    #list_eps = [0.005, 1, 10]\n",
    "    delta = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-burlington",
   "metadata": {},
   "source": [
    "## Synthesize the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-community",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_var = \"label\"\n",
    "rbo_p = 0.6\n",
    "\n",
    "# prepare data\n",
    "Xy = X_train.copy()\n",
    "Xy[\"label\"] = y_train\n",
    "Xy[cat_columns] = Xy[cat_columns].astype(\"int\")\n",
    "\n",
    "# --- loop over epsilons\n",
    "list_roc_auc = []\n",
    "list_f1 = []\n",
    "list_cosine = []\n",
    "list_rbo = []\n",
    "list_rbo_corr = []\n",
    "list_kl = []\n",
    "list_syn_features = []\n",
    "for eps in list_eps:\n",
    "    print(f\"--- EPS: {eps}\")\n",
    "    \n",
    "    if synthesizer_method == \"pgm\":\n",
    "        # train a PGM model\n",
    "        pgm = tabular_ppgm(target_variable=target_var, \n",
    "                           target_epsilon=eps, \n",
    "                           target_delta=delta)\n",
    "        pgm.train(Xy, iters=num_iters)\n",
    "        # generate synthetic output\n",
    "        synth_pd = pgm.generate(num_rows=len(Xy))\n",
    "    elif synthesizer_method == \"pate-ctgan\":\n",
    "        synth_pd = list_models[i].sample(len(Xy))\n",
    "    \n",
    "    # utility of synthetic data\n",
    "    Xsyn_train = synth_pd.drop(columns=[target_var]).astype(\"str\")\n",
    "    ysyn_train = synth_pd[target_var].to_list()\n",
    "    \n",
    "    f1_tmp, auc_tmp, roc_auc_tmp, f_syn_built, f_syn_perm, f_syn_shap = \\\n",
    "        tabular_metrics.performance_classification(Xsyn_train, ysyn_train, \n",
    "                                                   X_test, y_test, \n",
    "                                                   model_imp=custom_pipe,\n",
    "                                                   pipe_classifier_name=\"classifier\")\n",
    "    \n",
    "    # Sort the features\n",
    "    sorted_f_syn_built, _ = \\\n",
    "        tabular_utils.sort_feature_vector(f_syn_built, X_train.columns.to_list())\n",
    "    sorted_f_syn_perm, _  = \\\n",
    "        tabular_utils.sort_feature_vector(f_syn_perm,  X_train.columns.to_list())\n",
    "    sorted_f_syn_shap, sorted_f_syn_shap_val  = \\\n",
    "        tabular_utils.sort_feature_vector(f_syn_shap,  X_train.columns.to_list())\n",
    "    \n",
    "    \n",
    "    # cosine similarity between original and synthetic dataset\n",
    "    cosine_sim_measure = \\\n",
    "        tabular_metrics.cosine_sim(f_syn_shap, f_orig_shap)\n",
    "    \n",
    "    kl_div_measure = tabular_metrics.kl_div(f_syn_shap, f_orig_shap)\n",
    "    \n",
    "    # RBO\n",
    "    rbo = rbo_metric(sorted_f_orig_shap, sorted_f_syn_shap)\n",
    "    \n",
    "    # collect results\n",
    "    list_roc_auc.append(roc_auc_tmp)\n",
    "    list_f1.append(f1_tmp)\n",
    "    list_cosine.append(cosine_sim_measure)\n",
    "    list_rbo.append(rbo.rbo(p=rbo_p))\n",
    "    list_rbo_corr.append(\n",
    "        rbo.correlated_rank_similarity(p=rbo_p, \n",
    "                                       correlation_matrix=orig_corr_matrix))\n",
    "    list_kl.append(kl_div_measure)\n",
    "    list_syn_features.append(f_syn_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-coordinate",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_roc_auc\n",
    "orig_var = roc_auc_orig\n",
    "ylabel = \"ROC-AUC\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, \n",
    "            ls=\"--\", c=\"r\",\n",
    "            label=\"original\")\n",
    "plt.axhline(roc_auc_shuffled, \n",
    "            ls=\"--\", c=\"blue\",\n",
    "            label=\"shuffled\")\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_f1\n",
    "orig_var = f1_orig\n",
    "ylabel = \"F1\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, \n",
    "            ls=\"--\", c=\"r\",\n",
    "            label=\"original\")\n",
    "plt.axhline(f1_shuffled, \n",
    "            ls=\"--\", c=\"blue\",\n",
    "            label=\"shuffled\")\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ylabel = \"RBO score\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, list_rbo, \n",
    "         lw=3, marker=\"o\", c=\"k\",\n",
    "         label=\"RBO\")\n",
    "plt.plot(list_eps, list_rbo_corr, \n",
    "         lw=2, marker=\"o\", c=\"k\", ls=\"--\",\n",
    "         label=\"RBOcorr\")\n",
    "\n",
    "plt.axhline(1, \n",
    "            ls=\"--\", c=\"g\",\n",
    "            label=\"skyline\")\n",
    "plt.axhline(rbo_shuffled.rbo(p=0.6), \n",
    "            ls=\"--\", c=\"blue\",\n",
    "            label=\"RBO, shuffled\")\n",
    "plt.axhline(rbo_shuffled.correlated_rank_similarity(\n",
    "                p=0.6, correlation_matrix=orig_corr_matrix), \n",
    "            ls=\":\", c=\"blue\",\n",
    "            label=\"RBOcorr, shuffled\")\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_f_syn_shap)\n",
    "print(sorted_f_orig_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_orig_shap, f_shuffled_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "1. - spatial.distance.cosine(f_orig_shap, f_shuffled_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_f_orig_shap_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# original features\n",
    "plt.plot(f_orig_shap, c=\"r\", \n",
    "         lw=2, ls=\"--\", marker=\"o\",\n",
    "         label=\"original\")\n",
    "\n",
    "# original features\n",
    "plt.plot(f_shuffled_shap, c=\"b\", \n",
    "         lw=2, ls=\"--\", marker=\"o\",\n",
    "         label=\"shuffled\")\n",
    "\n",
    "# synthetic features\n",
    "colors = pl.cm.viridis_r(np.linspace(0.0,1,len(list_syn_features)))\n",
    "\n",
    "for i in range(len(list_syn_features)):\n",
    "    plt.plot(list_syn_features[i], c=colors[i], \n",
    "             lw=1., marker=\"o\", label=f\"$\\epsilon$:{list_eps[i]}\")\n",
    "\n",
    "plt.xlabel(\"Features\", size=20)\n",
    "plt.ylabel(\"Score\", size=20)\n",
    "\n",
    "list_features = X_train.columns.to_list()\n",
    "plt.xticks(range(len(list_features)), list_features, \n",
    "           size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_cosine\n",
    "orig_var = 1\n",
    "ylabel = \"Cosine sim\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, \n",
    "            ls=\"--\", c=\"r\",\n",
    "            label=\"original\")\n",
    "plt.axhline(cosine_sim_measure_shuffled, \n",
    "            ls=\"--\", c=\"b\",\n",
    "            label=\"shuffled\")\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_kl\n",
    "orig_var = 0\n",
    "ylabel = \"KL-divergence\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, \n",
    "            ls=\"--\", c=\"r\",\n",
    "            label=\"original\")\n",
    "plt.axhline(kl_div_measure_shuffled, \n",
    "            ls=\"--\", c=\"b\",\n",
    "            label=\"shuffled\")\n",
    "\n",
    "plt.xlabel(\"$\\epsilon$\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.legend(loc='center left', \n",
    "           bbox_to_anchor=(1, 0.5), \n",
    "           fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-conditioning",
   "metadata": {},
   "source": [
    "## Why cosine sim. between `f_shuffled_shap` and `f_orig_shap` is so high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of values for elements in random vectors\n",
    "min_val = 0\n",
    "max_val = 1000\n",
    "# Repetition\n",
    "num_iter = 1000000\n",
    "\n",
    "# list_dims = [  2,   3,   4,   5,   6,   7,   8,   9,   10, \n",
    "#               20,  30,  40,  50,  60,  70,  80,  90,  100, \n",
    "#              200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "list_dims = [2] + list(range(5, 105, 5))\n",
    "\n",
    "# --- list to collect results\n",
    "dims = []\n",
    "# cosine \n",
    "cs_means = []\n",
    "cs_stds = []\n",
    "# L2\n",
    "l2_means = []\n",
    "l2_stds = []\n",
    "\n",
    "\n",
    "# j specifies the dimension of random vectors\n",
    "for j in list_dims:\n",
    "    print(j, end=\" \")\n",
    "    \n",
    "    repetitions = range(num_iter)\n",
    "    tmp_cs_dists = []\n",
    "    tmp_l2_dists = []\n",
    "    x_used = []\n",
    "    \n",
    "    for i in repetitions:\n",
    "        \n",
    "        v1 = np.random.uniform(min_val, max_val, j)\n",
    "        # Weight some components?\n",
    "        # v1[:int(len(v1)/2)] *= 10\n",
    "        \n",
    "        # v2 is a permutation of v1\n",
    "        v2 = np.random.permutation(v1)\n",
    "        # v2 = np.random.uniform(min_val, max_val, j)\n",
    "\n",
    "        cs_sim  = tabular_metrics.cosine_sim(v1, v2)\n",
    "        l2_dist = tabular_metrics.L2_norm_dist(v1, v2)\n",
    "        \n",
    "        if isinstance(cs_sim, float) and isinstance(l2_dist, float):\n",
    "            tmp_cs_dists.append(cs_sim)\n",
    "            tmp_l2_dists.append(l2_dist)\n",
    "            x_used.append(i)\n",
    "            \n",
    "    tmp_cs_dists = np.array(tmp_cs_dists)\n",
    "    tmp_l2_dists = np.array(tmp_l2_dists)\n",
    "\n",
    "    tmp_noninf_cs_dists = tmp_cs_dists[tmp_cs_dists != np.inf]\n",
    "    curr_cs_mean = np.mean(tmp_noninf_cs_dists)\n",
    "    curr_cs_std  =  np.std(tmp_noninf_cs_dists)\n",
    "    \n",
    "    tmp_noninf_l2_dists = tmp_l2_dists[tmp_l2_dists != np.inf]\n",
    "    curr_l2_mean = np.mean(tmp_noninf_l2_dists)\n",
    "    curr_l2_std  =  np.std(tmp_noninf_l2_dists)\n",
    "    \n",
    "    dims.append(j)\n",
    "    \n",
    "    cs_means.append(curr_cs_mean)\n",
    "    cs_stds.append(curr_cs_std)\n",
    "    \n",
    "    l2_means.append(curr_l2_mean)\n",
    "    l2_stds.append(curr_l2_std)\n",
    "    \n",
    "#plt.scatter(x_act, dists, alpha=0.01, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-spread",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.errorbar(dims, cs_means, cs_stds, \n",
    "             c=\"k\", linestyle='None', marker='o')\n",
    "\n",
    "plt.xlabel(\"Dimension\", size=20)\n",
    "plt.ylabel(\"Cosine sim\", size=20)\n",
    "\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, 100)\n",
    "# plt.xscale(\"log\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_used, tmp_cs_dists, alpha=0.01, c='k')\n",
    "plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-appointment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (privgem_py38)",
   "language": "python",
   "name": "privgem_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
