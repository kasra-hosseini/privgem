{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "laughing-flower",
   "metadata": {},
   "source": [
    "# Artificial and synthetic datasets\n",
    "\n",
    "In this notebook, instead of using and synthesizing *real* datasets, we first create *artifical* datasets and then analyze the outputs. This way, we can engineer some required features in the artifical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve issue with autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from privgem import tabular_ppgm\n",
    "from privgem import tabular_metrics\n",
    "from privgem import tabular_utils\n",
    "from privgem import tabular_artificial\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1364)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-broad",
   "metadata": {},
   "source": [
    "## Create an artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "# Classes\n",
    "n_classes = 2\n",
    "class_weights = [0.5, 0.5]\n",
    "n_clusters_per_class = 1\n",
    "# Features\n",
    "n_features=5\n",
    "n_informative=5\n",
    "n_redundant=0\n",
    "n_repeated=0\n",
    "# Control \"noise\"\n",
    "flip_y=0.2\n",
    "class_sep=1.0\n",
    "\n",
    "# number of categorical columns and their bins\n",
    "n_categorical=5\n",
    "n_categorical_bins=[10, 5, 5, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, categories = \\\n",
    "    tabular_artificial.make_table(n_samples=n_samples,\n",
    "                                  n_classes=n_classes,\n",
    "                                  class_weights=class_weights,\n",
    "                                  n_clusters_per_class=n_clusters_per_class,\n",
    "                                  n_features=n_features, \n",
    "                                  n_informative=n_informative, \n",
    "                                  n_redundant=n_redundant, \n",
    "                                  n_repeated=n_repeated,\n",
    "                                  n_categorical=n_categorical,\n",
    "                                  n_categorical_bins=n_categorical_bins,\n",
    "                                  flip_y=flip_y, \n",
    "                                  class_sep=class_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-dover",
   "metadata": {},
   "source": [
    "## Utility of original/artifical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numerical and categorical columns\n",
    "num_columns, cat_columns = tabular_utils.extract_col_names_by_type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-lafayette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline\n",
    "custom_pipe = tabular_metrics.create_pipeline(num_columns, cat_columns, \n",
    "                                              categories=categories,\n",
    "                                              inp_classifer=RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "test_size=0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=test_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_orig, auc_orig, roc_auc_orig, features_orig = \\\n",
    "    tabular_metrics.performance_classification(X_train, y_train, \n",
    "                                               X_test, y_test, \n",
    "                                               model_imp=custom_pipe,\n",
    "                                               pipe_classifier_name=\"classifier\")\n",
    "\n",
    "print(f\"F1:       {f1_orig:.3f}\\n\"\\\n",
    "      f\"AUC:      {auc_orig:.3f}\\n\"\\\n",
    "      f\"ROC-AUC:  {roc_auc_orig:.3f}\\n\"\\\n",
    "      f\"Features: {features_orig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-forty",
   "metadata": {},
   "source": [
    "## Synthesize the artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-column",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iters = 1000\n",
    "list_eps = [0.005, 0.01, 0.1, 1, 5]\n",
    "delta = 1e-5\n",
    "target_var = \"label\"\n",
    "\n",
    "# prepare data\n",
    "Xy = X.copy()\n",
    "Xy[\"label\"] = y\n",
    "Xy = Xy.astype(\"int\")\n",
    "\n",
    "# --- loop over epsilons\n",
    "list_roc_auc = []\n",
    "list_f1 = []\n",
    "list_cosine = []\n",
    "for eps in list_eps:\n",
    "    print(f\"--- EPS: {eps}\")\n",
    "    # train a PGM model\n",
    "    pgm = tabular_ppgm(target_variable=target_var, \n",
    "                       target_epsilon=eps, \n",
    "                       target_delta=delta)\n",
    "    pgm.train(Xy, iters=num_iters)\n",
    "    # generate synthetic output\n",
    "    synth_pd = pgm.generate(num_rows=len(Xy))\n",
    "    \n",
    "    # utility of synthetic data\n",
    "    Xpgm_train = synth_pd.drop(columns=[target_var]).astype(\"str\")\n",
    "    ypgm_train = synth_pd[target_var].to_list()\n",
    "    \n",
    "    f1_tmp, auc_tmp, roc_auc_tmp, features_tmp = \\\n",
    "        tabular_metrics.performance_classification(Xpgm_train, ypgm_train, \n",
    "                                                   X_test, y_test, \n",
    "                                                   model_imp=custom_pipe,\n",
    "                                                   pipe_classifier_name=\"classifier\")\n",
    "    \n",
    "    # cosine similarity between original and synthetic dataset\n",
    "    cosine_sim_measure = \\\n",
    "        tabular_metrics.cosine_sim(features_orig, features_tmp)\n",
    "    \n",
    "    # collect results\n",
    "    list_roc_auc.append(roc_auc_tmp)\n",
    "    list_f1.append(f1_tmp)\n",
    "    list_cosine.append(cosine_sim_measure)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_roc_auc\n",
    "orig_var = roc_auc_orig\n",
    "ylabel = \"ROC-AUC\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, ls=\"--\", c=\"r\")\n",
    "\n",
    "plt.xlabel(\"Epsilon\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_f1\n",
    "orig_var = f1_orig\n",
    "ylabel = \"F1\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, ls=\"--\", c=\"r\")\n",
    "\n",
    "plt.xlabel(\"Epsilon\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "var2plot = list_cosine\n",
    "orig_var = 1\n",
    "ylabel = \"Cosine sim\"\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "plt.plot(list_eps, var2plot, \n",
    "         lw=3, marker=\"o\", c=\"k\")\n",
    "plt.axhline(orig_var, ls=\"--\", c=\"r\")\n",
    "\n",
    "plt.xlabel(\"Epsilon\", size=20)\n",
    "plt.ylabel(ylabel, size=20)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-berlin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (privgem_py38)",
   "language": "python",
   "name": "privgem_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
